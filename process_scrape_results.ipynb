{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211428bb-9006-4f65-9b27-09c484ccccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f67538-0002-4274-bc56-94270f839151",
   "metadata": {},
   "source": [
    "# Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf1c732-5808-490e-a1ef-bfb4a1506c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8810 False\n",
      "1420 False\n",
      "862\n",
      "0\n",
      "Index(['repo', 'id', 'author', 'sha', 'last_modified', 'created_at', 'private',\n",
      "       'gated', 'disabled', 'downloads', 'downloads_all_time', 'likes',\n",
      "       'library_name', 'gguf', 'inference', 'inference_provider_mapping',\n",
      "       'tags', 'pipeline_tag', 'mask_token', 'trending_score', 'card_data',\n",
      "       'widget_data', 'model_index', 'config', 'transformers_info', 'siblings',\n",
      "       'spaces', 'safetensors', 'security_repo_status', 'xet_enabled',\n",
      "       'lastModified', 'cardData', 'transformersInfo', '_id', 'modelId',\n",
      "       'usedStorage', 'total_downloads'],\n",
      "      dtype='object')\n",
      "Index(['repo', 'id', 'author', 'sha', 'created_at', 'last_modified', 'private',\n",
      "       'gated', 'disabled', 'downloads', 'downloads_all_time', 'likes',\n",
      "       'paperswithcode_id', 'tags', 'trending_score', 'card_data', 'siblings',\n",
      "       'xet_enabled', 'lastModified', 'cardData', '_id', 'usedStorage',\n",
      "       'description', 'citation', 'total_downloads'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "modeldf = pd.read_csv(\"hf_models_20250909_113720.csv\")\n",
    "dsdf = pd.read_csv(\"hf_datasets_20250909_114159.csv\")\n",
    "model_downloads = pd.read_csv(\"hf_model_downloads_20250909.csv\")\n",
    "dataset_downloads = pd.read_csv(\"hf_dataset_downloads_20250909.csv\")\n",
    "model_results_filename = \"hf_model_metadata_20250909_153100.jsonl\"\n",
    "dataset_results_filename = \"hf_dataset_metadata_20250909_152434.jsonl\"\n",
    "\n",
    "def get_json_records(filename):\n",
    "    records = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            repo = obj[\"id\"]\n",
    "            meta = obj[\"metadata\"]\n",
    "    \n",
    "            if meta == \"ERROR\":\n",
    "                # create a dict with just error marker\n",
    "                records.append({\"repo\": repo, \"ERROR\": True})\n",
    "            else:\n",
    "                # unpack metadata dict and add repo\n",
    "                row = {\"repo\": repo}\n",
    "                row.update(meta)\n",
    "                records.append(row)\n",
    "    return records\n",
    "\n",
    "mdf = pd.DataFrame(get_json_records(model_results_filename))\n",
    "ddf = pd.DataFrame(get_json_records(dataset_results_filename))\n",
    "\n",
    "mdf['total_downloads'] = mdf['repo'].map(dict(zip(model_downloads['model_id'], model_downloads['total_downloads'])))\n",
    "ddf['total_downloads'] = ddf['repo'].map(dict(zip(dataset_downloads['model_id'], dataset_downloads['total_downloads'])))\n",
    "\n",
    "# if no error then there will be no ERROR columns\n",
    "print(len(mdf), 'ERROR' in mdf.columns)\n",
    "print(len(ddf), 'ERROR' in ddf.columns)\n",
    "\n",
    "# if downloads weren't available they will be 0\n",
    "print(len(mdf[mdf['total_downloads'] == 0]))\n",
    "print(len(ddf[ddf['total_downloads'] == 0]))\n",
    "\n",
    "# column names for model and dataset metadata\n",
    "print(mdf.columns)\n",
    "print(ddf.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0541f-c8b5-47b3-b558-944e9cd7f586",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3015dd55-1eb3-4c81-a9d1-4dfede4ab9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8810\n",
      "8810\n",
      "8608\n"
     ]
    }
   ],
   "source": [
    "# --- helpers ---------------------------------------------------------------\n",
    "def _to_lower_list(x):\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        seq = x\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        seq = x.tolist()\n",
    "    else:\n",
    "        return []\n",
    "    return [str(t).lower() for t in seq if pd.notna(t)]\n",
    "    \n",
    "def _safe_str(x):\n",
    "    return str(x).lower() if pd.notna(x) else \"\"\n",
    "\n",
    "# Pipelines we do NOT want\n",
    "EXCLUDE_PIPELINES = {\n",
    "    # encoders / classifiers / embeddings\n",
    "    \"text-embedding\", \"feature-extraction\", \"sentence-similarity\",\n",
    "    \"fill-mask\", \"token-classification\", \"sequence-classification\",\n",
    "    # vision\n",
    "    \"image-classification\", \"object-detection\", \"image-segmentation\",\n",
    "    \"image-to-image\", \"depth-estimation\", \"image-feature-extraction\", # \"image-to-text\"\n",
    "    # audio\n",
    "    \"audio-classification\", \"text-to-speech\", # \"automatic-speech-recognition\",\n",
    "    \"speech-segmentation\", \"voice-activity-detection\",\n",
    "    # diffusion / generative imaging\n",
    "    \"text-to-image\", \"diffusers\",\n",
    "    # seq2seq (exclude T5-like)\n",
    "    \"text2text-generation\",\n",
    "}\n",
    "\n",
    "# Name/tag tokens we do NOT want (broad but conservative)\n",
    "EXCLUDE_NAME_TOKENS = {\n",
    "    # encoders / embedding families\n",
    "    \"bert\", \"roberta\", \"mpnet\", \"minilm\", \"e5\", \"bge\", \"gte\", \"sbert\", \"sentence-transformers\",\n",
    "    # t5 & friends\n",
    "    \"t5\",\n",
    "    # speech/asr/tts\n",
    "    \"whisper\", \"wav2vec\", \"hubert\", \"tacotron\", \"fastspeech\", \"tts\", \"vits\",\n",
    "    # diffusion / imaging\n",
    "    \"stable-diffusion\", \"sdxl\", \"sd-\", \"latent-diffusion\", \"controlnet\", \"unet\", \"vae\", \"inpaint\",\n",
    "    \"txt2img\", \"img2img\", \"diffusion\",\n",
    "}\n",
    "\n",
    "# Architectures we do NOT want (from config/architectures)\n",
    "EXCLUDE_ARCH_TOKENS = {\n",
    "    \"bert\", \"roberta\", \"t5\", \"whisper\", \"wav2vec\", \"hubert\",\n",
    "    # \"clip\", \"vision\", \"unet\", \"vae\",\n",
    "}\n",
    "\n",
    "# Positive signals for causal LMs and GGUF (known to be LLM format)\n",
    "INCLUDE_PIPELINES = {\"text-generation\"}\n",
    "INCLUDE_TAGS = {\"text-generation\", \"causal-lm\"}\n",
    "INCLUDE_NAME_TOKENS = {\"gguf\"}\n",
    "\n",
    "def is_decoder_only_llm(row) -> bool:\n",
    "    name = _safe_str(row.get(\"repo\") or row.get(\"modelId\") or row.get(\"id\"))\n",
    "    pipeline = _safe_str(row.get(\"pipeline_tag\"))\n",
    "    tags = set(_to_lower_list(row.get(\"tags\")))\n",
    "    cfg_str = _safe_str(row.get(\"config\"))\n",
    "    arch_str = _safe_str(row.get(\"transformers_info\") or row.get(\"transformersInfo\"))\n",
    "\n",
    "    # 1) Hard exclude by pipeline\n",
    "    if pipeline in EXCLUDE_PIPELINES:\n",
    "        return False\n",
    "\n",
    "    # 2) Positive signals: pipeline/tag says it's a causal LM\n",
    "    if pipeline in INCLUDE_PIPELINES:\n",
    "        return True\n",
    "\n",
    "    # 3) Hard include by name tokens or tags (\"strong\" list that applies first)\n",
    "    tags_hit = any(tag in tags for tag in INCLUDE_TAGS)\n",
    "    tokens_in_name = any(tok in name for tok in INCLUDE_NAME_TOKENS)\n",
    "    tokens_in_tags = any(tok in tags for tok in INCLUDE_NAME_TOKENS)\n",
    "    if tokens_in_name or tokens_in_tags:\n",
    "        return True\n",
    "        \n",
    "    # 4) Hard exclude by name tokens or tags\n",
    "    tokens_in_name = any(tok in name for tok in EXCLUDE_NAME_TOKENS)\n",
    "    tokens_in_tags = any(tok in tags for tok in EXCLUDE_NAME_TOKENS)\n",
    "    if tokens_in_name or tokens_in_tags:\n",
    "        return False\n",
    "\n",
    "    # 5) Hard exclude by architectures in config/transformers info\n",
    "    arch_blob = f\"{cfg_str} {arch_str}\"\n",
    "    if any(tok in arch_blob for tok in EXCLUDE_ARCH_TOKENS):\n",
    "        return False\n",
    "\n",
    "    # 6) Otherwise, include (change to False to be more conservative)\n",
    "    return True\n",
    "\n",
    "# --- apply filter -----------------------------------------------------------\n",
    "print(len(mdf))\n",
    "mdf = mdf.drop_duplicates(subset=[\"repo\"]).reset_index(drop=True)\n",
    "print(len(mdf))\n",
    "\n",
    "llmdf = mdf[mdf.apply(is_decoder_only_llm, axis=1)].reset_index(drop=True)\n",
    "print(len(llmdf))\n",
    "\n",
    "# # if need to examine the excluded repos\n",
    "# excluded = mdf[~mdf['repo'].isin(llmdf['repo'])][['id', 'tags', 'pipeline_tag', 'config', 'transformers_info', 'transformersInfo']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50760688-d4a4-453b-ad6b-dc22035db7a4",
   "metadata": {},
   "source": [
    "# Extract Metadata Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdcacc60-1955-46b2-b250-5f53be8988b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmdf[\"tags\"] = llmdf[\"tags\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "llmdf[\"config\"] = llmdf[\"config\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "llmdf[\"transformers_info\"] = llmdf[\"transformers_info\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "llmdf[\"transformersInfo\"] = llmdf[\"transformersInfo\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    if isinstance(x, dict):\n",
    "        if 'architectures' in x:\n",
    "            return x['architectures'][0]\n",
    "    return None\n",
    "llmdf['architectures'] = llmdf['config'].apply(f)\n",
    "\n",
    "def f(x):\n",
    "    if isinstance(x, dict):\n",
    "        if 'model_type' in x:\n",
    "            return x['model_type']\n",
    "    return None\n",
    "llmdf['model_type_extracted'] = llmdf['config'].apply(f)\n",
    "\n",
    "def f(x):\n",
    "    if isinstance(x, dict):\n",
    "        if 'parameters' in x:\n",
    "            if 'total' in x['parameters']:\n",
    "                return x['parameters']\n",
    "            else:\n",
    "                return max(x['parameters'].values(), default=None)\n",
    "    return None\n",
    "llmdf['parameters'] = llmdf['safetensors'].apply(f)\n",
    "\n",
    "model_type_list = llmdf['model_type_extracted'].value_counts().index\n",
    "\n",
    "def f(x):\n",
    "    repo, tags, model_type_extracted = x\n",
    "    if model_type_extracted:\n",
    "        return model_type_extracted\n",
    "    for model_type in model_type_list:\n",
    "        repo_hit = model_type.lower() in repo.lower()\n",
    "        tags_hit = any(model_type.lower() in tag.lower() for tag in tags)\n",
    "        if repo_hit or tags_hit:\n",
    "            return model_type\n",
    "    return None\n",
    "llmdf['model_type'] = llmdf[['repo', 'tags', 'model_type_extracted']].apply(f, axis=1)\n",
    "\n",
    "def f(x):\n",
    "    repo, tags = x\n",
    "    repo_hit = 'gguf' in repo.lower()\n",
    "    tags_hit = any('gguf' in tag.lower() for tag in tags)\n",
    "    return (repo_hit or tags_hit)\n",
    "llmdf['gguf'] = llmdf[['repo', 'tags']].apply(f, axis=1)\n",
    "\n",
    "def f(x):\n",
    "    repo, tags = x\n",
    "    repo_hit = 'merge' in repo.lower()\n",
    "    tags_hit = any('merge' in tag.lower() for tag in tags)\n",
    "    return (repo_hit or tags_hit)\n",
    "llmdf['merge_model'] = llmdf[['repo', 'tags']].apply(f, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c51dc-20cc-46f4-8d26-2630ddfe9b85",
   "metadata": {},
   "source": [
    "## Extract Quantization Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef3b425-d900-436a-a8eb-e71170cd2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUANT_TOKENS = {\n",
    "#     \"gptq\", \"awq\", \"exl2\", \"marlin\", \"spqr\", \"imatrix\",\n",
    "#     \"nf4\", \"fp4\", \"fp8\", \"fp16\", \"bf16\", \"fp32\",\n",
    "#     \"int4\", \"int8\", \"4-bit\", \"8-bit\"  # quick string hits\n",
    "# }\n",
    "\n",
    "# QUANT_REGEX = re.compile(\n",
    "#     r\"(?i)(?<![a-z0-9])(\"\n",
    "#     r\"q[234568](?:_[01])?\"\n",
    "#     r\"|q[234568]_k(?:_[sml])?\"\n",
    "#     r\"|iq[234568](?:_[a-z]{1,3})?\"\n",
    "#     r\"|q[45]f16(?:_[01])?\"\n",
    "#     r\"|int[2345678]\"\n",
    "#     r\"|[2345678]\\s*[-_ ]?\\s*bits?\"\n",
    "#     r\"|w[0-9]+a[0-9]+(?:g[0-9]+)?\"\n",
    "#     r\"|nf4|fp4|fp8|fp16|bf16|fp32\"\n",
    "#     r\"|gptq|awq|exl2|marlin|spqr|imatrix\"\n",
    "#     r\"|e[0-9]+b\"    # E4B etc.\n",
    "#     r\"|bpw[0-9]+(?:\\.[0-9]+)?\"   # bpw8, bpw4.0, bpw3.5\n",
    "#     r\"|[0-9]+(?:\\.[0-9]+)?bpw\"   # 5.0bpw, 4bpw\n",
    "#     r\")(?![a-z0-9])\"\n",
    "# )\n",
    "\n",
    "# def has_quant_signal(text: str) -> bool:\n",
    "#     if not text:\n",
    "#         return False\n",
    "#     s = text.lower()\n",
    "#     # quick pass for common tokens\n",
    "#     if any(tok in s for tok in QUANT_TOKENS):\n",
    "#         return True\n",
    "#     # structured patterns\n",
    "#     return bool(QUANT_REGEX.search(s))\n",
    "\n",
    "# def collect_quant_hits(*texts):\n",
    "#     \"\"\"Return sorted list of all quant tokens/regex matches found in given texts.\"\"\"\n",
    "#     hits = set()\n",
    "#     for t in texts:\n",
    "#         if not t:\n",
    "#             continue\n",
    "#         if isinstance(t, (list, tuple, set)):\n",
    "#             # scan each element if it's a list like tags\n",
    "#             for x in t:\n",
    "#                 s = str(x).lower()\n",
    "#                 hits.update(tok for tok in QUANT_TOKENS if tok in s)\n",
    "#                 hits.update(m.group(0).lower() for m in QUANT_REGEX.finditer(s))\n",
    "#         else:\n",
    "#             s = str(t).lower()\n",
    "#             hits.update(tok for tok in QUANT_TOKENS if tok in s)\n",
    "#             hits.update(m.group(0).lower() for m in QUANT_REGEX.finditer(s))\n",
    "#     return sorted(hits)\n",
    "\n",
    "# METHOD_TOKENS = {\"gptq\", \"awq\", \"exl2\", \"marlin\", \"spqr\", \"imatrix\"}  # add \"gguf\" if you want it as a type\n",
    "\n",
    "# def _token_bits(tok: str):\n",
    "#     s = str(tok).lower().strip()\n",
    "\n",
    "#     # weights-activations patterns like w8a8, w4a16, w8a8g128\n",
    "#     if s.startswith(\"w\") and \"a\" in s:\n",
    "#         i = 1\n",
    "#         w = \"\"\n",
    "#         while i < len(s) and s[i].isdigit():\n",
    "#             w += s[i]; i += 1\n",
    "#         k = s.find(\"a\", i)\n",
    "#         if k != -1:\n",
    "#             k += 1\n",
    "#             a = \"\"\n",
    "#             while k < len(s) and s[k].isdigit():\n",
    "#                 a += s[k]; k += 1\n",
    "#             bits = [int(x) for x in (w, a) if x]\n",
    "#             if bits:\n",
    "#                 return min(bits)  # choose the smaller of W/A as the quant level\n",
    "\n",
    "#     # bits-per-weight\n",
    "#     if s.startswith(\"bpw\"):\n",
    "#         num = \"\".join(ch for ch in s[3:] if (ch.isdigit() or ch == \".\"))\n",
    "#         if num:\n",
    "#             try:\n",
    "#                 return int(float(num))  # bpw8.0 → 8, bpw3.5 → 3\n",
    "#             except ValueError:\n",
    "#                 pass\n",
    "\n",
    "#     # bits-per-weight (suffix): 5.0bpw, 4bpw\n",
    "#     if s.endswith(\"bpw\"):\n",
    "#         num = \"\".join(ch for ch in s[:-3] if (ch.isdigit() or ch == \".\"))\n",
    "#         if num:\n",
    "#             try:\n",
    "#                 return int(float(num))  # 5.0bpw → 5\n",
    "#             except ValueError:\n",
    "#                 pass\n",
    "    \n",
    "#     # direct precision / bitwidth tokens\n",
    "#     if s in {\"fp32\"}: return 32\n",
    "#     if s in {\"bf16\", \"fp16\"}: return 16\n",
    "#     if s in {\"fp8\", \"int8\", \"8bit\", \"8-bit\"}: return 8\n",
    "#     if s in {\"fp4\", \"nf4\", \"int4\", \"4bit\", \"4-bit\"}: return 4\n",
    "#     if s in {\"int2\", \"2bit\", \"2-bit\"}: return 2\n",
    "        \n",
    "#     # generic N bit(s)\n",
    "#     if s.endswith(\"bit\") or s.endswith(\"bits\"):\n",
    "#         n = \"\".join(ch for ch in s if ch.isdigit())\n",
    "#         if n.isdigit():\n",
    "#             return int(n)\n",
    "\n",
    "#     # ExLlama-style: E4B, E5B, E8B\n",
    "#     if re.fullmatch(r\"e(\\d+)b\", s):\n",
    "#         return int(s[1:-1])\n",
    "            \n",
    "#     # q*/iq* families (e.g., q4, q8_0, q4f16_1, q5_k_s, iq4_xs, iq3_m)\n",
    "#     if s.startswith(\"iq\"):\n",
    "#         s = s[2:]\n",
    "#     elif s.startswith(\"q\"):\n",
    "#         s = s[1:]\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "#     # take leading digits after q/iq\n",
    "#     num = \"\"\n",
    "#     for ch in s:\n",
    "#         if ch.isdigit():\n",
    "#             num += ch\n",
    "#         else:\n",
    "#             break\n",
    "#     return int(num) if num else None\n",
    "\n",
    "# def get_quant_level_from_hits(hits):\n",
    "#     seq = hits if isinstance(hits, (list, tuple, set)) else ([hits] if hits else [])\n",
    "#     levels = [b for b in (_token_bits(t) for t in seq) if b is not None]\n",
    "#     return min(levels) if levels else 0  # choose the smallest level if multiple\n",
    "\n",
    "# def get_quant_type_from_hits(hits):\n",
    "#     seq = hits if isinstance(hits, (list, tuple, set)) else ([hits] if hits else [])\n",
    "#     methods = sorted({str(t).lower() for t in seq if str(t).lower() in METHOD_TOKENS})\n",
    "#     return \"+\".join(methods) if methods else \"quant\"\n",
    "\n",
    "# llmdf['quant_signal'] = llmdf['repo'].apply(has_quant_signal)\n",
    "# llmdf['quantization'] = llmdf['repo'].apply(collect_quant_hits)\n",
    "# llmdf['quant_level'] = llmdf['quantization'].apply(get_quant_level_from_hits)\n",
    "# llmdf['quant_type'] = llmdf['quantization'].apply(get_quant_type_from_hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da325844-311e-46f1-b7b9-192c6d3d7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANT_TOKENS = {\n",
    "    \"gptq\", \"awq\", \"exl2\", \"marlin\", \"spqr\", \"imatrix\", \"gguf\", \"ggml\",\n",
    "    \"nf4\", \"fp4\", \"fp8\", \"fp16\", \"bf16\", \"fp32\",\n",
    "    \"int4\", \"int8\", \"4-bit\", \"8-bit\",\n",
    "    \"q2_k\", \"q3_k\", \"q4_k\", \"q5_k\", \"q6_k\", \"q8_0\",  # GGUF-specific\n",
    "    \"iq1\", \"iq2\", \"iq3\", \"iq4\"  # imatrix GGUF variants\n",
    "}\n",
    "\n",
    "QUANT_REGEX = re.compile(\n",
    "    r\"(?i)(?<![a-z0-9])(\"\n",
    "    # GGUF/GGML patterns (most specific first)\n",
    "    r\"q[234568]_k(?:_[sml])?\"  # Q4_K_M, Q5_K_S, etc.\n",
    "    r\"|iq[1234]_[a-z]{1,3}\"     # IQ1_S, IQ2_XXS, IQ3_M, etc.\n",
    "    r\"|q[234568]_[01]\"          # Q4_0, Q4_1, Q8_0, etc.\n",
    "    r\"|q[234568]f16(?:_[01])?\"  # Q4f16_0, Q5f16_1\n",
    "    # Standard quantization patterns\n",
    "    r\"|q[234568](?![_])\"        # Plain Q2, Q3, Q4, etc. (but not Q4_K)\n",
    "    r\"|int[2345678]\"\n",
    "    r\"|[2345678]\\s*[-_ ]?\\s*bits?\"\n",
    "    # Weight-activation patterns\n",
    "    r\"|w[0-9]+a[0-9]+(?:g[0-9]+)?\"\n",
    "    # Precision formats\n",
    "    r\"|nf4|fp4|fp8|fp16|bf16|fp32\"\n",
    "    # Method names\n",
    "    r\"|gptq|awq|exl2|marlin|spqr|imatrix|gguf|ggml\"\n",
    "    # ExLlama patterns\n",
    "    r\"|e[0-9]+b\"\n",
    "    # Bits per weight\n",
    "    r\"|bpw[0-9]+(?:\\.[0-9]+)?\"\n",
    "    r\"|[0-9]+(?:\\.[0-9]+)?bpw\"\n",
    "    r\")(?![a-z0-9])\"\n",
    ")\n",
    "\n",
    "# Expanded method tokens to include GGUF/GGML\n",
    "METHOD_TOKENS = {\"gptq\", \"awq\", \"exl2\", \"marlin\", \"spqr\", \"imatrix\", \"gguf\", \"ggml\", \"hqq\", \"aqlm\", \"squeezellm\"}\n",
    "\n",
    "def has_quant_signal(text: str) -> bool:\n",
    "    if not text:\n",
    "        return False\n",
    "    s = text.lower()\n",
    "    # quick pass for common tokens\n",
    "    if any(tok in s for tok in QUANT_TOKENS):\n",
    "        return True\n",
    "    # structured patterns\n",
    "    return bool(QUANT_REGEX.search(s))\n",
    "\n",
    "def collect_quant_hits(*texts):\n",
    "    \"\"\"Return sorted list of all quant tokens/regex matches found in given texts.\"\"\"\n",
    "    hits = set()\n",
    "    for t in texts:\n",
    "        if not t:\n",
    "            continue\n",
    "        if isinstance(t, (list, tuple, set)):\n",
    "            for x in t:\n",
    "                s = str(x).lower()\n",
    "                hits.update(tok for tok in QUANT_TOKENS if tok in s)\n",
    "                hits.update(m.group(0).lower() for m in QUANT_REGEX.finditer(s))\n",
    "        else:\n",
    "            s = str(t).lower()\n",
    "            hits.update(tok for tok in QUANT_TOKENS if tok in s)\n",
    "            hits.update(m.group(0).lower() for m in QUANT_REGEX.finditer(s))\n",
    "    return sorted(hits)\n",
    "\n",
    "def _token_bits(tok: str):\n",
    "    s = str(tok).lower().strip()\n",
    "    \n",
    "    # GGUF/GGML quantization patterns (handle first)\n",
    "    if s.startswith(\"iq\"):\n",
    "        # IQ patterns: iq1_s → 1, iq2_xxs → 2, iq3_m → 3, iq4_xs → 4\n",
    "        if \"1\" in s: return 1\n",
    "        if \"2\" in s: return 2\n",
    "        if \"3\" in s: return 3\n",
    "        if \"4\" in s: return 4\n",
    "    \n",
    "    # Q patterns with underscores (GGUF style)\n",
    "    if re.match(r\"q[234568]_\", s):\n",
    "        # Q4_K_M → 4, Q5_K_S → 5, Q8_0 → 8, Q4f16_0 → 4\n",
    "        digits = re.search(r\"q(\\d+)\", s)\n",
    "        if digits:\n",
    "            return int(digits.group(1))\n",
    "    \n",
    "    # Plain Q patterns (must check after Q_)\n",
    "    if re.match(r\"q[234568]$\", s):\n",
    "        return int(s[1])\n",
    "\n",
    "    # weights-activations patterns\n",
    "    if s.startswith(\"w\") and \"a\" in s:\n",
    "        i = 1\n",
    "        w = \"\"\n",
    "        while i < len(s) and s[i].isdigit():\n",
    "            w += s[i]; i += 1\n",
    "        k = s.find(\"a\", i)\n",
    "        if k != -1:\n",
    "            k += 1\n",
    "            a = \"\"\n",
    "            while k < len(s) and s[k].isdigit():\n",
    "                a += s[k]; k += 1\n",
    "            bits = [int(x) for x in (w, a) if x]\n",
    "            if bits:\n",
    "                return min(bits)\n",
    "\n",
    "    # bits-per-weight patterns\n",
    "    bpw_match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*bpw\", s)\n",
    "    if not bpw_match:\n",
    "        bpw_match = re.search(r\"bpw\\s*(\\d+(?:\\.\\d+)?)\", s)\n",
    "    if bpw_match:\n",
    "        try:\n",
    "            return int(float(bpw_match.group(1)))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # direct precision tokens\n",
    "    if s in {\"fp32\"}: return 32\n",
    "    if s in {\"bf16\", \"fp16\"}: return 16\n",
    "    if s in {\"fp8\", \"int8\", \"8bit\", \"8-bit\", \"8 bit\", \"8 bits\"}: return 8\n",
    "    if s in {\"fp4\", \"nf4\", \"int4\", \"4bit\", \"4-bit\", \"4 bit\", \"4 bits\"}: return 4\n",
    "    if s in {\"int3\", \"3bit\", \"3-bit\", \"3 bit\", \"3 bits\"}: return 3\n",
    "    if s in {\"int2\", \"2bit\", \"2-bit\", \"2 bit\", \"2 bits\"}: return 2\n",
    "        \n",
    "    # N bit(s) patterns\n",
    "    bit_match = re.match(r\"(\\d+)\\s*[-_ ]?\\s*bits?$\", s)\n",
    "    if bit_match:\n",
    "        return int(bit_match.group(1))\n",
    "\n",
    "    # ExLlama patterns: E4B → 4\n",
    "    exl_match = re.match(r\"e(\\d+)b$\", s)\n",
    "    if exl_match:\n",
    "        return int(exl_match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_quant_level_from_hits(hits):\n",
    "    seq = hits if isinstance(hits, (list, tuple, set)) else ([hits] if hits else [])\n",
    "    levels = [b for b in (_token_bits(t) for t in seq) if b is not None]\n",
    "    return min(levels) if levels else 0\n",
    "\n",
    "def get_quant_type_from_hits(hits):\n",
    "    seq = hits if isinstance(hits, (list, tuple, set)) else ([hits] if hits else [])\n",
    "    seq_lower = [str(t).lower() for t in seq]\n",
    "    \n",
    "    # Check for GGUF/GGML specific patterns first\n",
    "    has_gguf_pattern = any(\n",
    "        re.match(r\"(q[234568]_[k01]|iq[1234]_)\", t) for t in seq_lower\n",
    "    )\n",
    "    if has_gguf_pattern or \"gguf\" in seq_lower or \"ggml\" in seq_lower:\n",
    "        return \"gguf\"\n",
    "    \n",
    "    # Check for other specific methods\n",
    "    methods = sorted({t for t in seq_lower if t in METHOD_TOKENS})\n",
    "    if methods:\n",
    "        # Return the most specific method if multiple\n",
    "        priority = [\"exl2\", \"awq\", \"gptq\", \"hqq\", \"aqlm\", \"marlin\", \"spqr\", \"imatrix\", \"squeezellm\"]\n",
    "        for p in priority:\n",
    "            if p in methods:\n",
    "                return p\n",
    "        return methods[0]\n",
    "    \n",
    "    # If we have quantization signals but no specific method\n",
    "    if seq_lower:\n",
    "        return \"quant\"\n",
    "    \n",
    "    return \"none\"\n",
    "\n",
    "# Apply to dataframe\n",
    "llmdf['quant_signal'] = llmdf['repo'].apply(has_quant_signal)\n",
    "llmdf['quantization'] = llmdf['repo'].apply(collect_quant_hits)\n",
    "llmdf['quant_level'] = llmdf['quantization'].apply(get_quant_level_from_hits)\n",
    "llmdf['quant_type'] = llmdf['quantization'].apply(get_quant_type_from_hits)\n",
    "\n",
    "# Optional: Add a column to identify mixed/hybrid quantization\n",
    "llmdf['is_mixed_quant'] = llmdf['quantization'].apply(\n",
    "    lambda hits: len(set(get_quant_level_from_hits([h]) for h in hits if get_quant_level_from_hits([h]))) > 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b2ce31a-ffb7-4279-8968-a7a2e9c75183",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmdf.to_pickle(\"llmdf.pkl\")\n",
    "llmdf.to_csv(\"repo_catalog.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37520641-ce72-44aa-bf8e-509732b7dbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
